<html>
<head>
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="main.css">
<script src="https://cdn.rawgit.com/showdownjs/showdown/1.9.1/dist/showdown.min.js">
</script>
<script language="javascript">
function run() {
	source = document.getElementById('markdown');
    target = document.getElementById('result');
    converter = new showdown.Converter();
    html = converter.makeHtml(source.innerHTML);
    target.innerHTML = html;    
}
window.onload = run;
</script>
<title>ML Made Easy - Advanced</title>
</head>
<body>
<div id="document">
<div class="header" id="myHeader">
	<div class="wide">
  <h1>ML Made Easy - Advanced</h1></div>
  <div class="narrow"><img class="right" src="intersystems.svg"/></div>
</div> 
<div id="markdown" style="display:none;">

## Introduction

In this exercise, you will use IntegratedML to create, train, and execute a predictive model on a sample data.

While the use case here is based on oversimplified case of predicting Iris flowers, IntegratedML can be used to solve all kinds of different problems with machine learning.

It is intended for developers who want to implement machine learning in their applications but do not have the expertise on hand to do so.

## Objectives

By the end of this exercise, you will be able to:

* Explain what IntegratedML is
* Create a model definition
* Train a model on a set of training data
* Execute a model on set of testing data
* Find and Observe the training process
* Validate a model and view the results
* Choose a different provider to train and test models
* Setting up different IntegratedML configurations
* How to view and maintain existing models

## View Data

Before you can begin to see the benefits of machine learning in an application, you first need to familiarize yourself with the data your application is receiving. 

In this exercise, you will work on two separate tables:

* **DataMining.IrisDataset** - This dataset contains the information of 150 different Iris flowers, with information of their petal and sepal width and length, and its sub-categorization into exact species (Iris Setosa, Iris Virginica, and Iris versicolor.

* **Titanic.Passenger** - List of passengers of Titanic's only journey along with information about their survival.

Your training (input) data should be a representative sample; it needs to be representative enough to give your machine learning engine sufficient data to identify patterns and relationships. 

In a real ML use cases, the training processs takes a considerable amount of time. It can take from 10-15 minutes to even couple of weeks to train, depending on the size of the dataset. For the sake of time, we have chosen small Iris flowers dataset.

In this exercise, the two sets of data are already prepared for use in a machine learning application. To learn about some of the key considerations you should think about when preparing your data for machine learning, you can refer to this [infographic](https://learning.intersystems.com/course/view.php?id=1415&ssoPass=1).

Run the SQL command below to view the Iris dataset table (your training data).
You can run this statement in the <a href="/csp/sys/exp/%25CSP.UI.Portal.SQL.Home.zen?$NAMESPACE=USER" target="_blank">embedded SQL editor</a>: 

	SELECT * FROM DataMining.IrisDataset

Scroll through the table to see the types of values included in each record. Each column contains the following information:

* sepal length in cm
* sepal width in cm
* petal length in cm
* petal width in cm
* class:
	- Iris Setosa
	- Iris Versicolour
	- Iris Virginica

To make it a bit more clear, each of the flower's properties are depicted in the following photos.

![Iris Flowers](https://shahinrostami.com/images/ml-with-kaggle/iris_class.png "Iris Flowers with depicted Sepal and Petal width and Length")

Before we get further, let's take a look at what is average sepal and petal width and length for each of the iris species.

	SELECT ROUND(AVG(PetalLength),1) as AVGPetalLength, ROUND(AVG(PetalWidth),1) as AVGPetalWidth, ROUND(AVG(SepalLength),1) as AVGSepalLength, ROUND(AVG(SepalWidth),1) as AVGSepalWidth, Species FROM DataMining.IrisDataset GROUP BY Species

You will receive result like this:

<table>
<tr>
<th>AVGPetalLength (cm)</th><th>AVGPetalWidth (cm)</th><th>AVGSepalLength (cm)</th><th>AVGSepalWidth (cm)</th><th>Species</th>
</tr>
<tr>
<td>1.5</td><td>0.2</td><td>5.0</td><td>3.4</td><td>IRIS-SETOSA</td>
</tr>
<tr>
<td>4.3</td><td>1.3</td><td>5.9</td><td>2.8</td><td>IRIS-VERSICOLOR</td>
</tr>
<tr>
<td>5.6</td><td>2.0</td><td>6.6</td><td>3.</td><td>IRIS-VIRGINICA</td>
</tr>
</table>

From the first look, we can notice that *IRIS-VIRGINICA* is the largest of the species, where *IRIS-SETOSA* is the smallest. We will use this "intuition" later-on.

## Create and Train a Predictive Model

Let's say that we want the machine to learn how to recognize the species of the flower based on its sepal and petal width and length.
This kind of problem, where we try to "classify" the flower based on various input parameters is called **classification problem**.

Once you have your training data and know what you are trying to predict, you can create a model definition in IntegratedML. 
To do this, a single line of SQL is required. Run the module below to create a model named FlowerPredictor.

	CREATE MODEL FlowerPredictor PREDICTING(species) from DataMining.IrisDataset

When you run this command in the <a href="/csp/sys/exp/%25CSP.UI.Portal.SQL.Home.zen?$NAMESPACE=USER" target="_blank">SQL editor</a> successfully, you will see  the result similar to something like the following:
Click here to open the <a href="/csp/sys/exp/%25CSP.UI.Portal.SQL.Home.zen?$NAMESPACE=USER" target="_blank">SQL editor</a> in a new window.

![CREATEMODELSS](createmodelss.png)

In the command above, you created a model definition for **FlowerPredictor** and specified that it will be predicting the **species** column from the **DataMining.IrisDataset** data set.
This command uses just the metadata about the dataset, namely the information about the columns like column type and size. The data itself is not being checked by `CREATE MODEL` statement.

Next, you can run the command below to train your **FlowerPredictor** model with the data set specified in the definition.
This statement usually takes the most of the time, but due to the fact that this dataset is small and simple, it is fast. 
Remember, IntegratedML is learning patterns and relationships across all columns and rows in DataMining.IrisDataset.
Click here to open the <a href="/csp/sys/exp/%25CSP.UI.Portal.SQL.Home.zen?$NAMESPACE=USER" target="_blank">SQL editor</a> in a new window.

	TRAIN MODEL FlowerPredictor

When it gets finshed, only result you will see it as follows:

![TRAINMODELSS](trainmodelss.png)

In this particular example, we trained the **FlowerPredictor** model without defining any specific dataset to train upon.
In this case, IntegratedML uses a dataset defined in `CREATE MODEL` statement.
However, throughout the lifetime of one ML use case, you might get additional data that you can use to make your ML makes even better forecasts. 
For that reason, `TRAIN MODEL` statement has optional, but essential, `FROM` option. This option enables you to "resume" training of your existing model.

In order to train this model, IntegratedML uses a machine learning provider. 
There are three primary machine learning providers available for use in IntegratedML:

- **AutoML** - a machine learning engine developed by InterSystems, housed in InterSystems IRIS
- **H2O** - an open-source automated machine learning platform
- **DataRobot** - an advanced enterprise automated machine learning platform

Later in this exercise, you will modify your ML Configuration to use different providers. Note that in order to use DataRobot, you need to be a DataRobot customer.

## Execute the Model

In two simple SQL commands, you have created and trained a model called FlowerPredictor that will predict the species of Iris Flower.

We can use this model to apply on new data. However, since we do not have any new data, we will be using the same dataset we used to train on.

Run the command below to return a table containing the original ID, the predicted species, and the actual species (already in the dataset) of the first 100 records.

	SELECT TOP 100 ID, PREDICT(FlowerPredictor) AS PredictedSpecies, Species AS ActualSpecies FROM DataMining.IrisDataset

Browse the results. You can see that the model performs perfectly. That is not always to be expected. 
As we noticed on the first look at dataset averages, we can very easily recognize flowers as their sizes are very distinctive.

To explore these results at a deeper level, you could select all rows (instead of just the top 100) and bring those results into other tool for analyzing how the model performed on your training data set. 
In the next section, you will see more options for assessing the model’s performance.
In addition to the `PREDICT` function, you can also utilize the `PROBABILITY` function in your results. 

Run the command below to return a table containing the original ID, the probability of for each of the species, the predicted species, and the actual species of the first 100 records.

	SELECT TOP 100 ID, 
		PROBABILITY(FlowerPredictor FOR 'Iris-setosa') AS SetosaProbability, 
		PROBABILITY(FlowerPredictor FOR 'Iris-versicolor') AS VersicolorProbability, 
		PROBABILITY(FlowerPredictor FOR 'Iris-virginica') AS VirginicaProbability, 
		PREDICT(FlowerPredictor) AS PredictedSpecies, 
		Species AS ActualSpecies 
			FROM DataMining.IrisDataset

Browse the results and look at how the probabilities IntegratedML calculated compare to the predictions it made. 
Naturally, higher probabilities tend to result in positive readmission predictions.
However, this does not necessarily follow a strict rule (like all probabilities above 0.50 equating to a positive prediction).

Notice that `FOR` clause within the brackets of `PROBABILITY` function. It is used to tell IntegratedML for which label it should show probability for. 
In case of Iris Dataset, it is the classifications '*Iris-setosa*', '*Iris-versicolor*' and '*Iris-virginica*'. 
Take care that these labels have to be entered case-sensitive.

When the results you are predicting are not classification choices, but just yes or no (1 or 0), 
you can use `PROBABILITY` function also without `FOR` clause. In that case, the default behavior would be `PROBABILITY(model-name FOR '1')`.

Let's try to give our FlowerPredictor custom values what our intuition would expect. 
As we saw on a table above, `Iris-virginica` is the largest flower, so let us see newly created model will recognize it as well.

	SELECT PREDICT(FlowerPredictor) as PredictedSpecies, 
			FROM 
				(SELECT 101 AS ID, 5 As PetalLength, 1.8 As PetalWidth, 6.1 As SepalLength, 2.9 As SepalWidth)

You will notice that the model have predicted correct species `Iris-virginica`.
Now try running the same query, just with ID AS 95.

	SELECT PREDICT(FlowerPredictor) as PredictedSpecies, 
		FROM 
			(SELECT 95 AS ID, 5 As PetalLength, 1.8 As PetalWidth, 6.1 As SepalLength, 2.9 As SepalWidth)

What is the prediction in this case?
The prediction has changed only because of different ID. 
Our common sense would tell us that ID of a row should have no influence to predicting species.
And this is correct. 
In our Iris Dataset, it is just a coincidence that that data was sorted so that first 50 flowers are Iris-setosa, second 50 iris-versicolor, and last 50 iris-virginica.
This has made our model to learn that for example if the ID is larger number, it is more likely to be 'Iris-virginica'.

AutoML providers usually rule out all unique ID-like columns before performing the training.
However, numeric ID values could represent a proxy to time axis as often data is entered in chronological order.
Therefore, all AutoML providers have built various mechanisms to balance this problem.

This example shows clearly that we need to take care of what data we feed to IntegratedML. 

Since we know ID represent no valuable information about Iris flowers, let us fix the issue.
First let us delete the previous model:

	DROP MODEL FlowerPredictor

`DROP MODEL` statement will drop the model definition along with all trained models performed.
We will create a new model, where we specifically define what should be used as inputs to train a model

	CREATE MODEL FlowerPredictor PREDICTING(Species) 
		WITH (PetalLength double, PetalWidth double, SepalLength double, SepalWidth double) 
		FROM DataMining.IrisDataset

We are using here `WITH` clause, where we directly define which columns should be considered by IntegratedML. 
Another way to `CREATE MODEL` for this case is also (you do not need to run this, as you have already created the model above):

  CREATE MODEL FLowerPredictor
		PREDICTING(Species) 
		FROM (
				SELECT PetalLength, PetalWidth, SepalLength, SepalWidth, Species FROM DataMining.IrisDataset
				)

Let's train the model again: 

	TRAIN MODEL FlowerPredictor

Now we can check again the prediction for our new model:

	SELECT PREDICT(FlowerPredictor), 
		FROM 
			(SELECT 5 As PetalLength, 1.8 As PetalWidth, 6.1 As SepalLength, 2.9 As SepalWidth)

Now we can see that we got a consistent prediction.

Utilizing both the `PREDICT` and `PROBABILITY` functions, you can assess how to best use the insights IntegratedML creates for your own application. 
In the next step, you will see how to validate a model in IntegratedML and see how accurate it is.

## Validate the Model

You may have looked at your results and assessed how well the model is performing against your testing data, 
but there is more information from a machine learning perspective that you can gather about your model’s accuracy.
Run the command below to create a validation metric for your predictive model based on your training data set.

	VALIDATE MODEL FlowerPredictor FROM DataMining.IrisDataset

Then, run the command below to view the data in the `%ML.ValidationMetric table`, which contains the results of your model validation.

	SELECT * FROM %ML.ValidationMetric

You can see that there are four metrics available that provide information about your model for each of the classes ('*Iris-setosa*','*Iris-versicolor*','*Iris-virginica*'):

- **Precision** - is a measure that reflects the number of actual positive results out of all predicted positive results; in this case, the percentage of predicted species that were actual species.
- **Recall** - is a measure that reflects the number of predicted positives out of all actual positives; in this case, the percentage of actual species that were predicted as such.
- **F-Measure** - is a measure that reflects the concerns of both Precision and Recall in one composite score.
- **Accuracy** - is a measure that reflects the overall percentage of predictions that were correct.

Using this information, you can understand how well your model performs. 
Ultimately, to really hone and refine a predictive model, a data scientist is eventually needed. 
However, knowing this information can help you, even without that expertise.

For instance, if we think of a real-life scenario, when choosing a model for patient readmissions, you may want to err on the side of being cautious 
(e.g., a preference toward predicting readmission when in doubt, letting fewer true readmissions go undetected). 
In cases like these, where the cost of a false negative can be high, you may opt for a model with a high Recall score.

## Train Models Using Different Configurations

Throughout the first four steps of this exercise, you have viewed your data, created a model, trained it, and validated it. 
Those steps have been completed using the default ML configuration for this IRIS instance.
An ML configuration is a collection of settings that IntegratedML uses to train a model. 
Primarily, a configuration specifies a machine learning provider that will perform training.

By default, IntegratedML uses the internal %AutoML configuration.
However, as we mentioned before, there are more providers that you can use: %H2O, %DataRobot, and %PMML.
In this exercise, we will use the %H2O configuration, which sets H2O as the machine learning provider.

You can see a short example of how to easily change providers and retrain an existing model. 
Run the command below to set the new default configuration to be %AutoML.

	SET ML CONFIGURATION %H2O

Setting this configuration will set the machine learning provider to be H2O.
Run the command below to re-train your `FlowerPredictor` model with the current configuration, naming the new version `FlowerPredictorV2`. 
Like last time, you will use the `DataMining.IrisDataset` data set for this training.

	TRAIN MODEL FlowerPredictor AS FlowerPredictorV2

Yes, this `TRAIN` statement looks different from the other one.
Although the `TRAIN MODEL FlowerPredictor` would in our case be sufficient, we made this `TRAIN` statement a bit more complex.
Notice the `AS` clause in above `TRAIN MODEL` statement. It is used to give name to this specific training session.
This can be very useful if you want to track versions of the ML models you train.
In the same manner, you can use exact model you trained to make predictions, as follows:

	SELECT PREDICT(FlowerPredictor USE FlowerPredictorV2) as PredictedSpeciesH20
			FROM 
				(SELECT 5 As PetalLength, 1.8 As PetalWidth, 6.1 As SepalLength, 2.9 As SepalWidth)

You will notice that the both models have predicted the correct species `Iris-virginica` .
Now try running the same query, just with ID AS 95.

	SELECT PREDICT(FlowerPredictor USE FlowerPredictorV2) as PredictedSpeciesH20, 
		PREDICT(FlowerPredictor USE FlowerPredictor2) as PredictedSpeciesAutoML 
		FROM 
			(SELECT 95 AS ID, 5 As PetalLength, 1.8 As PetalWidth, 6.1 As SepalLength, 2.9 As SepalWidth)

What is the prediction in this case?
The prediction has changed only because of different ID. 
Our common sense would tell us that ID of a row should have no influence to predicting species.
And this is correct. 

AutoML providers usually rule out all unique ID-like columns before performing the training.
However, numeric ID values could represent a proxy to time axis as often data is entered in chronological order.

This means that we need to take care of what data we feed to IntegratedML. 
Since we know ID represent no that is not the case for us, as the data was just accidentally sorted so that first 50 flowers are Iris-setosa, second 50 iris-versicolor, and last 50 iris-virginica.
This shows the importance of feeding the IntegratedML with only relevant data.
Let's fix this. We will create a new model, where we specially define what should be used as inputs to train a model

	CREATE MODEL FlowerPredictorX PREDICTING(Species) 
		WITH (PetalLength double, PetalWidth double, SepalLength double, SepalWidth double) 
		FROM DataMining.IrisDataset

We are using here `WITH` clause, where we directly define which columns should be considered by IntegratedML. 
Let's train this model: 

	TRAIN MODEL FlowerPredictorX

Now we can check again the prediction for our new model:

	SELECT PREDICT(FlowerPredictorX), 
		FROM 
			(SELECT 5 As PetalLength, 1.8 As PetalWidth, 6.1 As SepalLength, 2.9 As SepalWidth)

Now we can see that we got a consistent prediction.

Aside from using statement `SET ML CONFIGURATION` to change the IntegratedML settings, you can also use `USING` clause to train a model.
This is shown in the example below.

	TRAIN MODEL FlowerPredictorXY PREDICTING(Species) 
		WITH (PetalLength double, PetalWidth double, SepalLength double, SepalWidth double) 
		FROM DataMining.IrisDataset 
		USING {'provider':'H2O'}

Feel free to edit the SQL module below to experiment with the various commands you have learned for creating, training, and validating models as well as executing the PREDICT and PROBABILITY functions.



## Maintaining ML Models



## Observing the ML training runs

Let's take a look a bit deeper into the training process itself.

	SELECT * FROM INFORMATION_SCHEMA.ML_TRAINING_RUNS
	
Choose the last training run name (`TRAINING_RUN_NAME`) for the FlowerPredictor Model, and enter it into the following form. 
This small CSP script will enable you to see the TrainingRun in a pretty format.

<form name="trainingLog" method="get" action="trainingLog.csp" target="_blank">
<p>Training Run: <input type="text" name="trainingrun">
<input type="submit" value="Show Training Run" ></p>
</form>


## Summary and Additional Resources

You have now completed Getting Started with IntegratedML. In this exercise, you:
* Created a model definition
* Trained a model on a set of training data
* Executed a model on set of testing data
* Validated a model and view the results
* Set a different ML configuration to train new models

To learn more about IntegratedML, visit the following learning resources:

* [Learn IntegratedML in InterSystems IRIS® - resource guide](https://learning.intersystems.com/course/view.php?id=1346&ssoPass=1)
* [Using IntegratedML - Documentation](https://docs.intersystems.com/iris20202/csp/docbook/Doc.View.cls?KEY=GIML)


</div>
<div class="markdown-body" id="result" style="margin-left:25px;">
</div>
</div>
</body>
</html>